{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Federated Learning CTG",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQzk9r8TpARV"
      },
      "source": [
        "import pandas as pd\n",
        "X_test = pd.read_csv('/content/drive/MyDrive/iot_magazine2020/x_test_resampled.csv', header=None)\n",
        "X_test=X_test.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jti1Tv2hq8u2",
        "outputId": "cc93f490-cc60-40e0-f6c2-762b7105900f"
      },
      "source": [
        "len(X_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8uc-zONsAD8"
      },
      "source": [
        "#!pip install keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qjFf6yrRqLDZ",
        "outputId": "bf30fb54-4a10-4512-8ae5-0f98483ef7da"
      },
      "source": [
        "import keras\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "y_test = pd.read_csv('/content/drive/MyDrive/iot_magazine2020/y_test_resampled.csv', header=None)\n",
        "y_test= y_test.values.reshape((len(y_test.values),1))\n",
        "y_test = to_categorical(y_test)\n",
        "y_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMhLsHvUqcwc",
        "outputId": "f6a89f2a-779e-452a-ca11-1cce7eeb7051"
      },
      "source": [
        "import tensorflow as tf\n",
        "import collections\n",
        "\n",
        "x_data_fed = []\n",
        "y_data_fed = []\n",
        "x_data_fed2 = []\n",
        "y_data_fed2 = []\n",
        "x_data_fed3 = []\n",
        "y_data_fed3 = []\n",
        "x_data_fed4 = []\n",
        "y_data_fed4 = []\n",
        "\n",
        "data = []\n",
        "data2 = []\n",
        "data3= []\n",
        "data4 = []\n",
        "\n",
        "\n",
        "counter = 0\n",
        "for i in range(25):\n",
        "  x_data_fed.append([i.reshape(-1,21,1)[0] for i in X_test[counter:counter+10]])\n",
        "  y_data_fed.append([i.reshape(-1,4)[0] for i in y_test[counter:counter+10]])\n",
        "  counter=counter+10\n",
        "for i in range(25):\n",
        "  data.append(tf.data.Dataset.from_tensors(collections.OrderedDict(x=x_data_fed[i]  , y=y_data_fed[i] )))\n",
        "\n",
        "print(counter)\n",
        "\n",
        "for i in range(25):\n",
        "  x_data_fed2.append([i.reshape(-1,21,1)[0] for i in X_test[counter:counter+10]])\n",
        "  y_data_fed2.append([i.reshape(-1,4)[0] for i in y_test[counter:counter+10]])\n",
        "  counter=counter+10\n",
        "for i in range(25):\n",
        "  data2.append(tf.data.Dataset.from_tensors(collections.OrderedDict(x=x_data_fed2[i]  , y=y_data_fed2[i] )))\n",
        "\n",
        "print(counter)\n",
        "\n",
        "for i in range(25):\n",
        "  x_data_fed3.append([i.reshape(-1,21,1)[0] for i in X_test[counter:counter+10]])\n",
        "  y_data_fed3.append([i.reshape(-1,4)[0] for i in y_test[counter:counter+10]])\n",
        "  counter=counter+10\n",
        "for i in range(25):\n",
        "  data3.append(tf.data.Dataset.from_tensors(collections.OrderedDict(x=x_data_fed3[i]  , y=y_data_fed3[i] )))\n",
        "\n",
        "print(counter)\n",
        "\n",
        "for i in range(25):\n",
        "  x_data_fed4.append([i.reshape(-1,21,1)[0] for i in X_test[counter:counter+10]])\n",
        "  y_data_fed4.append([i.reshape(-1,4)[0] for i in y_test[counter:counter+10]])\n",
        "  counter=counter+10\n",
        "\n",
        "for i in range(25):\n",
        "  data4.append(tf.data.Dataset.from_tensors(collections.OrderedDict(x=x_data_fed4[i]  , y=y_data_fed4[i] )))\n",
        "\n",
        "print(counter)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(counter)\n",
        "print(data[0].element_spec)\n",
        "print(data2[0].element_spec)\n",
        "print(data3[0].element_spec)\n",
        "print(data4[0].element_spec)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "250\n",
            "500\n",
            "750\n",
            "1000\n",
            "1000\n",
            "OrderedDict([('x', TensorSpec(shape=(10, 21, 1), dtype=tf.float64, name=None)), ('y', TensorSpec(shape=(10, 4), dtype=tf.float32, name=None))])\n",
            "OrderedDict([('x', TensorSpec(shape=(10, 21, 1), dtype=tf.float64, name=None)), ('y', TensorSpec(shape=(10, 4), dtype=tf.float32, name=None))])\n",
            "OrderedDict([('x', TensorSpec(shape=(10, 21, 1), dtype=tf.float64, name=None)), ('y', TensorSpec(shape=(10, 4), dtype=tf.float32, name=None))])\n",
            "OrderedDict([('x', TensorSpec(shape=(10, 21, 1), dtype=tf.float64, name=None)), ('y', TensorSpec(shape=(10, 4), dtype=tf.float32, name=None))])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-giZ-0RtpaDg",
        "outputId": "c3f57ba5-0013-4072-a90c-4997ac9d7f5f"
      },
      "source": [
        "!pip install tensorflow_federated_nightly\n",
        "!pip install nest_asyncio Set up an Image Classification Model \n",
        "!pip install tb-nightly  # or tensorboard, but not both\n",
        "\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow_federated as tff\n",
        "import pickle\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow_federated_nightly\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/16/0e/27df0eff12bbdaecb15c4361aac59802bcbce2891666ae0aab8c6aa51d5b/tensorflow_federated_nightly-0.19.0.dev20210703-py2.py3-none-any.whl (675kB)\n",
            "\r\u001b[K     |▌                               | 10kB 14.6MB/s eta 0:00:01\r\u001b[K     |█                               | 20kB 9.8MB/s eta 0:00:01\r\u001b[K     |█▌                              | 30kB 8.4MB/s eta 0:00:01\r\u001b[K     |██                              | 40kB 7.6MB/s eta 0:00:01\r\u001b[K     |██▍                             | 51kB 4.1MB/s eta 0:00:01\r\u001b[K     |███                             | 61kB 4.3MB/s eta 0:00:01\r\u001b[K     |███▍                            | 71kB 4.6MB/s eta 0:00:01\r\u001b[K     |███▉                            | 81kB 5.1MB/s eta 0:00:01\r\u001b[K     |████▍                           | 92kB 5.4MB/s eta 0:00:01\r\u001b[K     |████▉                           | 102kB 4.3MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 112kB 4.3MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 122kB 4.3MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 133kB 4.3MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 143kB 4.3MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 153kB 4.3MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 163kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 174kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 184kB 4.3MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 194kB 4.3MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 204kB 4.3MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 215kB 4.3MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 225kB 4.3MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 235kB 4.3MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 245kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 256kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 266kB 4.3MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 276kB 4.3MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 286kB 4.3MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 296kB 4.3MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 307kB 4.3MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 317kB 4.3MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 327kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████████                | 337kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 348kB 4.3MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 358kB 4.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 368kB 4.3MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 378kB 4.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 389kB 4.3MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 399kB 4.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 409kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 419kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 430kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 440kB 4.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 450kB 4.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 460kB 4.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 471kB 4.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 481kB 4.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 491kB 4.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 501kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 512kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 522kB 4.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 532kB 4.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 542kB 4.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 552kB 4.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 563kB 4.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 573kB 4.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 583kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 593kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 604kB 4.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 614kB 4.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 624kB 4.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 634kB 4.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 645kB 4.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 655kB 4.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 665kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 675kB 4.3MB/s \n",
            "\u001b[?25hCollecting cachetools~=3.1.1\n",
            "  Downloading https://files.pythonhosted.org/packages/2f/a6/30b0a0bef12283e83e58c1d6e7b5aabc7acfc4110df81a4471655d33e704/cachetools-3.1.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: jax~=0.2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow_federated_nightly) (0.2.13)\n",
            "Collecting tensorflow-privacy~=0.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/63/aaaf4eb040bc8f4f2d145c3d9b3324e0fae3a61fdd471a5fa6d3988832aa/tensorflow_privacy-0.6.1-py3-none-any.whl (219kB)\n",
            "\u001b[K     |████████████████████████████████| 225kB 29.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: retrying~=1.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow_federated_nightly) (1.3.3)\n",
            "Collecting tensorflow-model-optimization~=0.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/55/38/4fd48ea1bfcb0b6e36d949025200426fe9c3a8bfae029f0973d85518fa5a/tensorflow_model_optimization-0.5.0-py2.py3-none-any.whl (172kB)\n",
            "\u001b[K     |████████████████████████████████| 174kB 51.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: jaxlib~=0.1.55 in /usr/local/lib/python3.7/dist-packages (from tensorflow_federated_nightly) (0.1.66+cuda110)\n",
            "Collecting attrs~=19.3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/a2/db/4313ab3be961f7a763066401fb77f7748373b6094076ae2bda2806988af6/attrs-19.3.0-py2.py3-none-any.whl\n",
            "Collecting tf-nightly\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3e/80/971bee0e759c9274ba926789c226a7ae4a9fba4c2c66250c1b1a9a80cf87/tf_nightly-2.7.0.dev20210708-cp37-cp37m-manylinux2010_x86_64.whl (456.4MB)\n",
            "\u001b[K     |████████████████████████████████| 456.4MB 33kB/s \n",
            "\u001b[?25hCollecting tqdm~=4.28.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/55/8cb23a97301b177e9c8e3226dba45bb454411de2cbd25746763267f226c2/tqdm-4.28.1-py2.py3-none-any.whl (45kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow_federated_nightly) (0.1.6)\n",
            "Requirement already satisfied: portpicker~=1.3.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow_federated_nightly) (1.3.9)\n",
            "Collecting semantic-version~=2.8.5\n",
            "  Downloading https://files.pythonhosted.org/packages/a5/15/00ef3b7888a10363b7c402350eda3acf395ff05bebae312d1296e528516a/semantic_version-2.8.5-py2.py3-none-any.whl\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow_federated_nightly) (1.19.5)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow_federated_nightly) (0.12.0)\n",
            "Collecting grpcio~=1.37.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/31/d8/1bfe90cc49c166dd2ec1be46fa4830c254ce702004a110830c74ec1df0c0/grpcio-1.37.1-cp37-cp37m-manylinux2014_x86_64.whl (4.2MB)\n",
            "\u001b[K     |████████████████████████████████| 4.2MB 27.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: opt-einsum in /usr/local/lib/python3.7/dist-packages (from jax~=0.2.8->tensorflow_federated_nightly) (3.3.0)\n",
            "Requirement already satisfied: tensorflow-estimator>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-privacy~=0.6.0->tensorflow_federated_nightly) (2.5.0)\n",
            "Requirement already satisfied: scipy>=0.17 in /usr/local/lib/python3.7/dist-packages (from tensorflow-privacy~=0.6.0->tensorflow_federated_nightly) (1.4.1)\n",
            "Requirement already satisfied: mpmath in /usr/local/lib/python3.7/dist-packages (from tensorflow-privacy~=0.6.0->tensorflow_federated_nightly) (1.2.1)\n",
            "Requirement already satisfied: six>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from retrying~=1.3.3->tensorflow_federated_nightly) (1.15.0)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.7/dist-packages (from jaxlib~=0.1.55->tensorflow_federated_nightly) (1.12)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly->tensorflow_federated_nightly) (3.1.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tf-nightly->tensorflow_federated_nightly) (0.36.2)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tf-nightly->tensorflow_federated_nightly) (1.12.1)\n",
            "Collecting tf-estimator-nightly~=2.7.0.dev\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a2/4d/8ed0f2ea85e040f7f4b35708fff89728a8c614577e864a0b084dc7099536/tf_estimator_nightly-2.7.0.dev2021070801-py2.py3-none-any.whl (463kB)\n",
            "\u001b[K     |████████████████████████████████| 471kB 45.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tf-nightly->tensorflow_federated_nightly) (3.7.4.3)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tf-nightly->tensorflow_federated_nightly) (1.1.2)\n",
            "Collecting libclang~=11.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8c/2d/acd22bf061f8057c68ac1cef1312cd1f42c4da5542820cf3434694405de4/libclang-11.1.0-py2.py3-none-manylinux1_x86_64.whl (12.8MB)\n",
            "\u001b[K     |████████████████████████████████| 12.8MB 151kB/s \n",
            "\u001b[?25hRequirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly->tensorflow_federated_nightly) (0.4.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tf-nightly->tensorflow_federated_nightly) (1.6.3)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tf-nightly->tensorflow_federated_nightly) (0.2.0)\n",
            "Collecting tb-nightly~=2.6.0.a\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1f/09/85c6dc95a80911baa95e0c9370951bd92416b789d92707c1717dec640da0/tb_nightly-2.6.0a20210708-py3-none-any.whl (5.5MB)\n",
            "\u001b[K     |████████████████████████████████| 5.5MB 33.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tf-nightly->tensorflow_federated_nightly) (3.12.4)\n",
            "Collecting keras-nightly~=2.7.0.dev\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f4/21/160ca2ce589e5e04720350fdcde63b56f2a177deffa143b53ab21be925eb/keras_nightly-2.7.0.dev2021070800-py2.py3-none-any.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 26.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly->tensorflow_federated_nightly) (1.1.0)\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tf-nightly->tensorflow_federated_nightly) (1.5.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.6.0.a->tf-nightly->tensorflow_federated_nightly) (0.4.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.6.0.a->tf-nightly->tensorflow_federated_nightly) (3.3.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.6.0.a->tf-nightly->tensorflow_federated_nightly) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.6.0.a->tf-nightly->tensorflow_federated_nightly) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.6.0.a->tf-nightly->tensorflow_federated_nightly) (1.8.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.6.0.a->tf-nightly->tensorflow_federated_nightly) (57.0.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.6.0.a->tf-nightly->tensorflow_federated_nightly) (1.0.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.6.0.a->tf-nightly->tensorflow_federated_nightly) (1.31.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tb-nightly~=2.6.0.a->tf-nightly->tensorflow_federated_nightly) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tb-nightly~=2.6.0.a->tf-nightly->tensorflow_federated_nightly) (4.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.6.0.a->tf-nightly->tensorflow_federated_nightly) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.6.0.a->tf-nightly->tensorflow_federated_nightly) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.6.0.a->tf-nightly->tensorflow_federated_nightly) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.6.0.a->tf-nightly->tensorflow_federated_nightly) (3.0.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tb-nightly~=2.6.0.a->tf-nightly->tensorflow_federated_nightly) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tb-nightly~=2.6.0.a->tf-nightly->tensorflow_federated_nightly) (0.2.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tb-nightly~=2.6.0.a->tf-nightly->tensorflow_federated_nightly) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tb-nightly~=2.6.0.a->tf-nightly->tensorflow_federated_nightly) (3.4.1)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tb-nightly~=2.6.0.a->tf-nightly->tensorflow_federated_nightly) (0.4.8)\n",
            "\u001b[31mERROR: tensorflow 2.5.0 has requirement grpcio~=1.34.0, but you'll have grpcio 1.37.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.5.0 has requirement keras-nightly~=2.5.0.dev, but you'll have keras-nightly 2.7.0.dev2021070800 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: spacy 2.2.4 has requirement tqdm<5.0.0,>=4.38.0, but you'll have tqdm 4.28.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: pymc3 3.11.2 has requirement cachetools>=4.2.1, but you'll have cachetools 3.1.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fbprophet 0.7.1 has requirement tqdm>=4.36.1, but you'll have tqdm 4.28.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-privacy 0.6.1 has requirement attrs>=21.2.0, but you'll have attrs 19.3.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: cachetools, attrs, tensorflow-privacy, tensorflow-model-optimization, grpcio, tf-estimator-nightly, libclang, tb-nightly, keras-nightly, tf-nightly, tqdm, semantic-version, tensorflow-federated-nightly\n",
            "  Found existing installation: cachetools 4.2.2\n",
            "    Uninstalling cachetools-4.2.2:\n",
            "      Successfully uninstalled cachetools-4.2.2\n",
            "  Found existing installation: attrs 21.2.0\n",
            "    Uninstalling attrs-21.2.0:\n",
            "      Successfully uninstalled attrs-21.2.0\n",
            "  Found existing installation: grpcio 1.34.1\n",
            "    Uninstalling grpcio-1.34.1:\n",
            "      Successfully uninstalled grpcio-1.34.1\n",
            "  Found existing installation: keras-nightly 2.5.0.dev2021032900\n",
            "    Uninstalling keras-nightly-2.5.0.dev2021032900:\n",
            "      Successfully uninstalled keras-nightly-2.5.0.dev2021032900\n",
            "  Found existing installation: tqdm 4.41.1\n",
            "    Uninstalling tqdm-4.41.1:\n",
            "      Successfully uninstalled tqdm-4.41.1\n",
            "Successfully installed attrs-19.3.0 cachetools-3.1.1 grpcio-1.37.1 keras-nightly-2.7.0.dev2021070800 libclang-11.1.0 semantic-version-2.8.5 tb-nightly-2.6.0a20210708 tensorflow-federated-nightly-0.19.0.dev20210703 tensorflow-model-optimization-0.5.0 tensorflow-privacy-0.6.1 tf-estimator-nightly-2.7.0.dev2021070801 tf-nightly-2.7.0.dev20210708 tqdm-4.28.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "keras",
                  "tensorboard",
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.7/dist-packages (1.5.1)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement Set (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for Set\u001b[0m\n",
            "Requirement already satisfied: tb-nightly in /usr/local/lib/python3.7/dist-packages (2.6.0a20210708)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tb-nightly) (0.36.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly) (1.8.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tb-nightly) (0.12.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tb-nightly) (1.31.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly) (3.12.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tb-nightly) (3.3.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tb-nightly) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly) (2.23.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tb-nightly) (1.37.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly) (0.6.1)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly) (1.19.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly) (57.0.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tb-nightly) (0.4.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.4->tb-nightly) (1.15.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tb-nightly) (3.1.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tb-nightly) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tb-nightly) (0.2.8)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tb-nightly) (4.5.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tb-nightly) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tb-nightly) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tb-nightly) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tb-nightly) (2021.5.30)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tb-nightly) (1.3.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tb-nightly) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tb-nightly) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tb-nightly) (3.7.4.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tb-nightly) (3.1.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VycLcp91s6yR"
      },
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "\n",
        "\n",
        "loaded_model = load_model('/content/drive/MyDrive/iot_magazine2020/CTG_resampled.h5')\n",
        "\n",
        "\n",
        "opt=keras.optimizers.Adam()\n",
        "loaded_model.compile(optimizer=opt,\n",
        "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1Fsf2rFtNsR",
        "outputId": "d2e9d83a-c5be-4ed3-9a99-cf88f582d4b4"
      },
      "source": [
        "def model_fn():\n",
        "  # We _must_ create a new model here, and _not_ capture it from an external\n",
        "  # scope. TFF will call this within different graph contexts.\n",
        "  keras_model = tf.keras.models.clone_model(loaded_model)\n",
        "  return tff.learning.from_keras_model(\n",
        "      keras_model,\n",
        "      input_spec=data[0].element_spec,\n",
        "      loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "      metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
        "  \n",
        "iterative_process = tff.learning.build_federated_averaging_process(\n",
        "    model_fn,\n",
        "    client_optimizer_fn=lambda: tf.keras.optimizers.Adam(),\n",
        "    server_optimizer_fn=lambda: tf.keras.optimizers.Adam())\n",
        "  \n",
        "state = iterative_process.initialize()\n",
        "\n",
        "state = tff.learning.state_with_new_model_weights(\n",
        "    state,\n",
        "    trainable_weights=[v.numpy() for v in loaded_model.trainable_weights],\n",
        "    non_trainable_weights=[\n",
        "        v.numpy() for v in loaded_model.non_trainable_weights\n",
        "    ])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/normalization.py:534: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method _KerasModel.__init__.<locals>._WeightedMeanLossMetric.update_state of <tensorflow_federated.python.learning.keras_utils._KerasModel.__init__.<locals>._WeightedMeanLossMetric object at 0x7f73d4f25590>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('update_state_fn',), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <bound method _KerasModel.__init__.<locals>._WeightedMeanLossMetric.update_state of <tensorflow_federated.python.learning.keras_utils._KerasModel.__init__.<locals>._WeightedMeanLossMetric object at 0x7f73d4f25590>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('update_state_fn',), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['lstm_2/lstm_cell/kernel:0', 'lstm_2/lstm_cell/recurrent_kernel:0', 'lstm_2/lstm_cell/bias:0', 'lstm_3/lstm_cell_1/kernel:0', 'lstm_3/lstm_cell_1/recurrent_kernel:0', 'lstm_3/lstm_cell_1/bias:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_federated/python/core/impl/compiler/tensorflow_computation_transformations.py:60: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_federated/python/core/impl/compiler/tensorflow_computation_transformations.py:60: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WENzwtyKtbqy"
      },
      "source": [
        "loaded_model2 = load_model('/content/drive/MyDrive/iot_magazine2020/CTG_resampled.h5', compile=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7wcZ-oqXtjFp",
        "outputId": "06a29372-5c39-4e31-a2e7-46610f0ef1ea"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "y_test2 = pd.read_csv('/content/drive/MyDrive/iot_magazine20#from RegscorePy import *\n",
        "\n",
        "print('Round {r}'.format(r=1))20/y_test_resampled.csv', header=None)\n",
        "y_test2= y_test2.values.reshape((len(y_test2.values),1))\n",
        "x_test2 = pd.read_csv('/content/drive/MyDrive/iot_magazine2020/x_test_resampled.csv', header=None)\n",
        "x_test2= x_test2.values.reshape((len(x_test2),21,1))\n",
        "print(x_test2.shape)\n",
        "\n",
        "def keras_evaluate(state, round_num):\n",
        "  # Take our global model weights and push them back into a Keras model to\n",
        "  # use its standard `.evaluate()` method.\n",
        "  keras_model = loaded_model2\n",
        "  keras_model.compile(\n",
        "      loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "      metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
        "  state.model.assign_weights_to(keras_model)\n",
        "  loss, accuracy = keras_model.evaluate(x_test2[counter:],y_test[counter:] )\n",
        "  print('\\tEval: loss={l:.3f}, accuracy={a:.3f}'.format(l=loss, a=accuracy))\n",
        "  predz = keras_model.predict(x_test2[counter:]).argmax(axis=-1)\n",
        "  print(classification_report(y_test2[counter:],predz) )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2000, 21, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULlv40RttquA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13168b30-da42-4340-8ef3-6b09f1ff60b4"
      },
      "source": [
        "#from RegscorePy import *\n",
        "\n",
        "print('Round {r}'.format(r=1))\n",
        "state, metrics = iterative_process.next(state, data)\n",
        "train_metrics = metrics['train']\n",
        "print(\" train mterics: \", train_metrics)\n",
        "keras_evaluate(state, 1)\n",
        "\n",
        "print('Round {r}'.format(r=2))\n",
        "state, metrics = iterative_process.next(state, data2)\n",
        "train_metrics = metrics['train']\n",
        "print(\"mterics: \", train_metrics)\n",
        "keras_evaluate(state, 2)\n",
        "\n",
        "\n",
        "\n",
        "print('Round {r}'.format(r=3))\n",
        "state, metrics = iterative_process.next(state, data3)\n",
        "train_metrics = metrics['train']\n",
        "print(\"mterics: \", train_metrics)\n",
        "keras_evaluate(state, 3)\n",
        "\n",
        "\n",
        "\n",
        "print('Round {r}'.format(r=4))\n",
        "state, metrics = iterative_process.next(state, data4)\n",
        "train_metrics = metrics['train']\n",
        "print(\"mterics: \", train_metrics)\n",
        "keras_evaluate(state, 4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Round 1\n",
            " train mterics:  OrderedDict([('categorical_accuracy', 0.624), ('loss', 1.18585)])\n",
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f73d4e26200> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f73d4e26200> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f73d4e26200> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/backend.py:4870: UserWarning: \"`categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  [0. 0. 0.]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "32/32 [==============================] - 1s 11ms/step - loss: 0.0805 - categorical_accuracy: 0.9730\n",
            "\tEval: loss=0.081, accuracy=0.973\n",
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7f73c3aa63b0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7f73c3aa63b0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7f73c3aa63b0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.94      0.97       337\n",
            "           2       0.94      0.99      0.96       336\n",
            "           3       0.99      0.99      0.99       327\n",
            "\n",
            "    accuracy                           0.97      1000\n",
            "   macro avg       0.97      0.97      0.97      1000\n",
            "weighted avg       0.97      0.97      0.97      1000\n",
            "\n",
            "Round 2\n",
            "mterics:  OrderedDict([('categorical_accuracy', 0.944), ('loss', 0.10444429)])\n",
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f73d51a3950> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f73d51a3950> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f73d51a3950> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "32/32 [==============================] - 1s 12ms/step - loss: 0.0876 - categorical_accuracy: 0.9710\n",
            "\tEval: loss=0.088, accuracy=0.971\n",
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7f73c21ef8c0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7f73c21ef8c0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7f73c21ef8c0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.93      0.96       337\n",
            "           2       0.93      0.99      0.96       336\n",
            "           3       0.99      0.99      0.99       327\n",
            "\n",
            "    accuracy                           0.97      1000\n",
            "   macro avg       0.97      0.97      0.97      1000\n",
            "weighted avg       0.97      0.97      0.97      1000\n",
            "\n",
            "Round 3\n",
            "mterics:  OrderedDict([('categorical_accuracy', 0.944), ('loss', 0.17616767)])\n",
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f73c23aa050> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f73c23aa050> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f73c23aa050> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "32/32 [==============================] - 1s 12ms/step - loss: 0.0926 - categorical_accuracy: 0.9680\n",
            "\tEval: loss=0.093, accuracy=0.968\n",
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7f73c21eff80> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7f73c21eff80> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7f73c21eff80> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.92      0.96       337\n",
            "           2       0.92      0.99      0.96       336\n",
            "           3       0.99      0.99      0.99       327\n",
            "\n",
            "    accuracy                           0.97      1000\n",
            "   macro avg       0.97      0.97      0.97      1000\n",
            "weighted avg       0.97      0.97      0.97      1000\n",
            "\n",
            "Round 4\n",
            "mterics:  OrderedDict([('categorical_accuracy', 0.976), ('loss', 0.06058333)])\n",
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f73c215b290> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f73c215b290> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f73c215b290> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "32/32 [==============================] - 1s 12ms/step - loss: 0.1020 - categorical_accuracy: 0.9670\n",
            "\tEval: loss=0.102, accuracy=0.967\n",
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7f73c23fc050> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7f73c23fc050> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7f73c23fc050> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.92      0.96       337\n",
            "           2       0.92      0.99      0.95       336\n",
            "           3       0.98      0.99      0.99       327\n",
            "\n",
            "    accuracy                           0.97      1000\n",
            "   macro avg       0.97      0.97      0.97      1000\n",
            "weighted avg       0.97      0.97      0.97      1000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}